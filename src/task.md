# Задание на русском языке

## Задача 00: Масштабируемость

Со временем доска была покрыта записями.

- **Доступ через командную строку** — должна быть отдельная программа, которая предоставляет REPL (Read-Eval-Print Loop) и подключается к работающему экземпляру через сеть, даже если это просто локальный хост и порт.
  
- **Управление процессами** — мы должны иметь возможность завершить любой экземпляр (процесс) базы данных, и он должен продолжать работать и предоставлять ответы на запросы. Это означает, что одним из настраиваемых параметров должен быть фактор репликации, т.е. сколько копий одного и того же документа мы храним. Для тестирования, вероятно, 2 достаточно.

- **Механизм пульсации** — клиент должен выполнять пульсации, чтобы проверить, доступен ли текущий экземпляр базы данных. Если он перестает отвечать, клиент должен автоматически переключиться на другой экземпляр.

- **Осведомленность о нодах** — для простоты предположим, что масштабируемость означает, что клиент должен знать обо всех других узлах. Любой ответ на пульсацию от текущего узла должен включать все известные адреса и порты экземпляров, а также текущий фактор репликации.

Таким образом, нам нужно реализовать две программы — одна является клиентом, а другая — экземпляром базы данных. Каждый раз, когда вы запускаете новый экземпляр, вы должны иметь возможность указать его на существующий экземпляр, чтобы после получения пульсации он отправил свой хост и порт всем другим работающим узлам, и все узлы знали о новом экземпляре.

Если узел экземпляра запускается с другим фактором репликации, чем существующие узлы, он должен это обнаружить и автоматически завершить работу, не присоединяясь к кластеру. Это означает, что фактор репликации также должен быть включен в пульсацию.

Вы можете использовать любой сетевой протокол для этого — HTTP, gRPC и т.д. Когда фактор репликации больше, чем количество работающих узлов, информация об этой проблеме должна быть включена в пульсацию и явно отображаться в каждом подключенном клиенте. Пример пользовательской сессии можно увидеть в Задаче 01. Фактическая работа с документами будет реализована в следующей задаче.

## Глава V

## Задача 01: Балансировка и Запросы

"Хорошо, давайте использовать строки UUID4 в качестве ключей артефактов. Нам также нужно реализовать некоторую балансировку для обеспечения отказоустойчивости..."

Наша простая база данных должна поддерживать только три операции — GET, SET и DELETE.

Вот как должна выглядеть типичная сессия, с комментариями (начинающимися с #):

```bash
~$ ./warehouse-cli -H 127.0.0.1 -P 8765
Connected to a database of Warehouse 13 at 127.0.0.1:8765
Known nodes:
127.0.0.1:8765
127.0.0.1:9876
127.0.0.1:8697
> SET 12345 '{"name": "Chapayev's Mustache comb"}'
Error: Key is not a proper UUID4
> SET 0d5d3807-5fbf-4228-a657-5a091c4e497f '{"name": "Chapayev's Mustache comb"}'
Created (2 replicas)
> GET 0d5d3807-5fbf-4228-a657-5a091c4e497f
'{"name": "Chapayev's Mustache comb"}'
> DELETE 0d5d3807-5fbf-4228-a657-5a091c4e497f
Deleted (2 replicas)
> GET 0d5d3807-5fbf-4228-a657-5a091c4e497f
Not found
>
# if current instance is stopped in the background
Reconnected to a database of Warehouse 13 at 127.0.0.1:8697
Known nodes:
127.0.0.1:9876
127.0.0.1:8697
> 
# if another current instance is stopped in the background
Reconnected to a database of Warehouse 13 at 127.0.0.1:9876
Known nodes:
127.0.0.1:9876
WARNING: cluster size (1) is smaller than a replication factor (2)!

>
```

Если ключ, указанный в SET, уже существует в базе данных, значение должно быть перезаписано. Если его нет, то операция SET должна обеспечивать консистентность чтения после записи, что означает, что немедленное чтение должно возвращать правильное значение. 

При обновлении или удалении существующего значения должна быть реализована конечная консистентность, что означает, что немедленные (грязные) чтения могут (но не "должны") возвращать старые результаты, но через несколько секунд данные должны быть обновлены до правильного нового состояния.

Вы можете реализовать балансировку на основе хеширования ключей, чтобы ваш клиент мог явно вычислить для каждой записи список узлов, где она должна храниться в соответствии с фактором репликации. Это также полезно для удаления.

Если текущий узел будет остановлен во время записи, ваш клиент должен автоматически запросить другой доступный узел. Единственный случай, когда пользователь должен увидеть ошибку "Не удалось записать/прочитать запись", — это когда все экземпляры мертвы.

## Глава VI

## Задача 02: Да здравствует король

Давайте обновим логику из Задач 00/01. Теперь мы вводим концепции узла Лидера и Узла Подписчика. Это приводит к ряду важных изменений:

- С этого момента клиент взаимодействует ТОЛЬКО с узлом Лидером. Хеш-функция для определения, куда записывать реплики, теперь находится на Лидере, а не в клиенте.

- Все узлы (Лидер и Подписчики) продолжают отправлять друг другу пульсации с полным списком узлов. Если узел не отвечает на пульсации в течение определенного настраиваемого времени ожидания (для тестирования вы должны установить его на 10 секунд по умолчанию).

- Если Лидер остановлен, оставшиеся Подписчики должны иметь возможность выбрать нового Лидера из числа них. Для простоты каждый из них может просто отсортировать список узлов по какому-либо другому уникальному идентификатору (числовой идентификатор, порт и т.д.) и выбрать первый. С этого момента все пульсации будут содержать нового избранного Лидера.

- Если клиент не может подключиться к известному Лидеру, он должен попытаться подключиться к Подписчикам, чтобы получить пульсацию от них. Если Лидер убит, эта пульсация будет содержать нового избранного Лидера.

## Глава VII

## Задача 03: Консенсус

**ПРИМЕЧАНИЕ**: эта задача полностью необязательна. Она оценивается только как бонусная часть.

Вы могли заметить, что в приведенной выше схеме может произойти множество ошибок, в частности, гонки условий и возможность потери данных, поскольку реплики не автоматически синхронизируются между экземплярами после того, как некоторые из них выходят из строя. 

Вы можете попробовать исправить это для получения дополнительных баллов, либо используя существующее решение, либо написав обходной путь самостоятельно. Вот несколько вариантов:

- Используйте существующую реализацию Raft (https://github.com/hashicorp/raft) или напишите минимальную реализацию сами.
- Используйте внешние инструменты, такие как Zookeeper (https://zookeeper.apache.org/) или Etcd (https://etcd.io/).
- Идите другим путем, например, Paxos (https://github.com/kkdai/paxos), некоторыми реализациями блокчейна (например, https://tendermint.com/) или своими собственными решениями.

...Надеюсь, теперь Пит и Майка не придется проходить через кучу бумажной работы каждый раз, когда им нужно что-то найти. Вероятно, Арти всё равно это сделает, потому что иногда действительно трудно бросить привычку. Но я думаю, что это было интересное путешествие, и мы нашли несколько классных артефактов на этом пути. А вы?